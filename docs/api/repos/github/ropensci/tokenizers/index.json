{"parser": "github", "uid": "github/ropensci/tokenizers", "url": "https://github.com/ropensci/tokenizers", "data": {"timestamp": "2022-01-26 19:13:46.229164", "name": "tokenizers", "url": "https://api.github.com/repos/ropensci/tokenizers", "full_name": "ropensci/tokenizers", "html_url": "https://github.com/ropensci/tokenizers", "private": false, "description": "Fast, Consistent Tokenization of Natural Language Text", "created_at": "2016-03-25T04:16:33Z", "updated_at": "2022-01-15T14:45:23Z", "clone_url": "https://github.com/ropensci/tokenizers.git", "homepage": "https://docs.ropensci.org/tokenizers", "size": 1278, "stargazers_count": 167, "watchers_count": 167, "language": "R", "open_issues_count": 3, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "owner": {"html_url": "https://github.com/ropensci", "avatar_url": "https://avatars.githubusercontent.com/u/1200269?v=4", "login": "ropensci", "type": "Organization"}, "topics": ["text-mining", "tokenizer", "rstats", "nlp", "r", "r-package", "peer-reviewed"]}}
